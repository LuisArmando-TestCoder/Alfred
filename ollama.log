time=2026-02-20T16:25:00.835-06:00 level=INFO source=routes.go:1511 msg="server config" env="map[HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/Users/luisarmandooriens/.ollama/models OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false http_proxy: https_proxy: no_proxy:]"
time=2026-02-20T16:25:00.850-06:00 level=INFO source=images.go:522 msg="total blobs: 10"
time=2026-02-20T16:25:00.851-06:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2026-02-20T16:25:00.858-06:00 level=INFO source=routes.go:1564 msg="Listening on 127.0.0.1:11434 (version 0.12.6)"
time=2026-02-20T16:25:00.861-06:00 level=INFO source=runner.go:80 msg="discovering available GPUs..."
time=2026-02-20T16:25:01.219-06:00 level=INFO source=types.go:112 msg="inference compute" id=0 library=Metal compute=0.0 name=Metal description="Apple M1" libdirs="" driver=0.0 pci_id=00:00.0 type=discrete total="5.3 GiB" available="5.3 GiB"
time=2026-02-20T16:25:01.219-06:00 level=INFO source=routes.go:1605 msg="entering low vram mode" "total vram"="5.3 GiB" threshold="20.0 GiB"
[GIN] 2026/02/20 - 16:25:10 | 200 |    2.802459ms |       127.0.0.1 | GET      "/api/tags"
ggml_metal_library_init: using embedded metal library
ggml_metal_library_init: loaded in 11.232 sec
ggml_metal_device_init: GPU name:   Apple M1
ggml_metal_device_init: GPU family: MTLGPUFamilyApple7  (1007)
ggml_metal_device_init: GPU family: MTLGPUFamilyCommon3 (3003)
ggml_metal_device_init: GPU family: MTLGPUFamilyMetal4  (5002)
ggml_metal_device_init: simdgroup reduction   = true
ggml_metal_device_init: simdgroup matrix mul. = true
ggml_metal_device_init: has unified memory    = true
ggml_metal_device_init: has bfloat            = true
ggml_metal_device_init: use residency sets    = true
ggml_metal_device_init: use shared buffers    = true
ggml_metal_device_init: recommendedMaxWorkingSetSize  =  5726.63 MB
llama_model_load_from_file_impl: using device Metal (Apple M1) (unknown id) - 5460 MiB free
llama_model_loader: loaded meta data with 29 key-value pairs and 292 tensors from /Users/luisarmandooriens/.ollama/models/blobs/sha256-667b0c1932bc6ffc593ed1d03f895bf2dc8dc6df21db3042284a6f4416b06a29 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Meta Llama 3.1 8B Instruct
llama_model_loader: - kv   3:                           general.finetune str              = Instruct
llama_model_loader: - kv   4:                           general.basename str              = Meta-Llama-3.1
llama_model_loader: - kv   5:                         general.size_label str              = 8B
llama_model_loader: - kv   6:                            general.license str              = llama3.1
llama_model_loader: - kv   7:                               general.tags arr[str,6]       = ["facebook", "meta", "pytorch", "llam...
llama_model_loader: - kv   8:                          general.languages arr[str,8]       = ["en", "de", "fr", "it", "pt", "hi", ...
llama_model_loader: - kv   9:                          llama.block_count u32              = 32
llama_model_loader: - kv  10:                       llama.context_length u32              = 131072
llama_model_loader: - kv  11:                     llama.embedding_length u32              = 4096
llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 14336
llama_model_loader: - kv  13:                 llama.attention.head_count u32              = 32
llama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  17:                          general.file_type u32              = 15
llama_model_loader: - kv  18:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  24:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  28:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   66 tensors
llama_model_loader: - type q4_K:  193 tensors
llama_model_loader: - type q6_K:   33 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 4.58 GiB (4.89 BPW) 
load: printing all EOG tokens:
load:   - 128001 ('<|end_of_text|>')
load:   - 128008 ('<|eom_id|>')
load:   - 128009 ('<|eot_id|>')
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: vocab_only       = 1
print_info: model type       = ?B
print_info: model params     = 8.03 B
print_info: general.name     = Meta Llama 3.1 8B Instruct
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128001 '<|end_of_text|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128001 '<|end_of_text|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
llama_model_load: vocab only - skipping tensors
time=2026-02-20T16:27:25.114-06:00 level=INFO source=server.go:400 msg="starting runner" cmd="/Applications/Ollama.app/Contents/Resources/ollama runner --model /Users/luisarmandooriens/.ollama/models/blobs/sha256-667b0c1932bc6ffc593ed1d03f895bf2dc8dc6df21db3042284a6f4416b06a29 --port 56028"
time=2026-02-20T16:27:25.120-06:00 level=INFO source=server.go:505 msg="system memory" total="8.0 GiB" free="1.2 GiB" free_swap="0 B"
time=2026-02-20T16:27:25.121-06:00 level=INFO source=memory.go:36 msg="new model will fit in available VRAM across minimum required GPUs, loading" model=/Users/luisarmandooriens/.ollama/models/blobs/sha256-667b0c1932bc6ffc593ed1d03f895bf2dc8dc6df21db3042284a6f4416b06a29 library=Metal parallel=1 required="5.2 GiB" gpus=1
time=2026-02-20T16:27:25.121-06:00 level=INFO source=server.go:545 msg=offload library=Metal layers.requested=-1 layers.model=33 layers.offload=33 layers.split=[33] memory.available="[5.3 GiB]" memory.gpu_overhead="0 B" memory.required.full="5.2 GiB" memory.required.partial="5.2 GiB" memory.required.kv="512.0 MiB" memory.required.allocations="[5.2 GiB]" memory.weights.total="4.3 GiB" memory.weights.repeating="3.9 GiB" memory.weights.nonrepeating="411.0 MiB" memory.graph.full="296.0 MiB" memory.graph.partial="296.0 MiB"
time=2026-02-20T16:27:25.185-06:00 level=INFO source=runner.go:893 msg="starting go runner"
ggml_metal_library_init: using embedded metal library
ggml_metal_library_init: loaded in 11.067 sec
ggml_metal_device_init: GPU name:   Apple M1
ggml_metal_device_init: GPU family: MTLGPUFamilyApple7  (1007)
ggml_metal_device_init: GPU family: MTLGPUFamilyCommon3 (3003)
ggml_metal_device_init: GPU family: MTLGPUFamilyMetal4  (5002)
ggml_metal_device_init: simdgroup reduction   = true
ggml_metal_device_init: simdgroup matrix mul. = true
ggml_metal_device_init: has unified memory    = true
ggml_metal_device_init: has bfloat            = true
ggml_metal_device_init: use residency sets    = true
ggml_metal_device_init: use shared buffers    = true
ggml_metal_device_init: recommendedMaxWorkingSetSize  =  5726.63 MB
time=2026-02-20T16:27:25.189-06:00 level=INFO source=ggml.go:104 msg=system Metal.0.EMBED_LIBRARY=1 CPU.0.NEON=1 CPU.0.ARM_FMA=1 CPU.0.FP16_VA=1 CPU.0.DOTPROD=1 CPU.0.LLAMAFILE=1 CPU.0.ACCELERATE=1 compiler=cgo(clang)
time=2026-02-20T16:27:36.326-06:00 level=INFO source=runner.go:929 msg="Server listening on 127.0.0.1:56028"
time=2026-02-20T16:27:36.331-06:00 level=INFO source=runner.go:828 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:false KvSize:4096 KvCacheType: NumThreads:4 GPULayers:33[ID:0 Layers:33(0..32)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:true}"
llama_model_load_from_file_impl: using device Metal (Apple M1) (unknown id) - 5460 MiB free
time=2026-02-20T16:27:36.332-06:00 level=INFO source=server.go:1272 msg="waiting for llama runner to start responding"
time=2026-02-20T16:27:36.332-06:00 level=INFO source=server.go:1306 msg="waiting for server to become available" status="llm server loading model"
llama_model_loader: loaded meta data with 29 key-value pairs and 292 tensors from /Users/luisarmandooriens/.ollama/models/blobs/sha256-667b0c1932bc6ffc593ed1d03f895bf2dc8dc6df21db3042284a6f4416b06a29 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Meta Llama 3.1 8B Instruct
llama_model_loader: - kv   3:                           general.finetune str              = Instruct
llama_model_loader: - kv   4:                           general.basename str              = Meta-Llama-3.1
llama_model_loader: - kv   5:                         general.size_label str              = 8B
llama_model_loader: - kv   6:                            general.license str              = llama3.1
llama_model_loader: - kv   7:                               general.tags arr[str,6]       = ["facebook", "meta", "pytorch", "llam...
llama_model_loader: - kv   8:                          general.languages arr[str,8]       = ["en", "de", "fr", "it", "pt", "hi", ...
llama_model_loader: - kv   9:                          llama.block_count u32              = 32
llama_model_loader: - kv  10:                       llama.context_length u32              = 131072
llama_model_loader: - kv  11:                     llama.embedding_length u32              = 4096
llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 14336
llama_model_loader: - kv  13:                 llama.attention.head_count u32              = 32
llama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  17:                          general.file_type u32              = 15
llama_model_loader: - kv  18:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  24:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  28:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   66 tensors
llama_model_loader: - type q4_K:  193 tensors
llama_model_loader: - type q6_K:   33 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 4.58 GiB (4.89 BPW) 
load: printing all EOG tokens:
load:   - 128001 ('<|end_of_text|>')
load:   - 128008 ('<|eom_id|>')
load:   - 128009 ('<|eot_id|>')
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_embd           = 4096
print_info: n_layer          = 32
print_info: n_head           = 32
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: is_swa_any       = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 4
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 14336
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: model type       = 8B
print_info: model params     = 8.03 B
print_info: general.name     = Meta Llama 3.1 8B Instruct
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128001 '<|end_of_text|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128001 '<|end_of_text|>'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)

load_tensors: offloading 32 repeating layers to GPU
load_tensors: offloading output layer to GPU
load_tensors: offloaded 33/33 layers to GPU
load_tensors:   CPU_Mapped model buffer size =   281.81 MiB
load_tensors: Metal_Mapped model buffer size =  4403.49 MiB
llama_init_from_model: model default pooling_type is [0], but [-1] was specified
llama_context: constructing llama_context
llama_context: n_seq_max     = 1
llama_context: n_ctx         = 4096
llama_context: n_ctx_per_seq = 4096
llama_context: n_batch       = 512
llama_context: n_ubatch      = 512
llama_context: causal_attn   = 1
llama_context: flash_attn    = disabled
llama_context: kv_unified    = false
llama_context: freq_base     = 500000.0
llama_context: freq_scale    = 1
llama_context: n_ctx_per_seq (4096) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
ggml_metal_init: allocating
ggml_metal_init: picking default device: Apple M1
ggml_metal_init: use bfloat         = true
ggml_metal_init: use fusion         = true
ggml_metal_init: use concurrency    = true
ggml_metal_init: use graph optimize = true
llama_context:        CPU  output buffer size =     0.50 MiB
llama_kv_cache:      Metal KV buffer size =   512.00 MiB
llama_kv_cache: size =  512.00 MiB (  4096 cells,  32 layers,  1/1 seqs), K (f16):  256.00 MiB, V (f16):  256.00 MiB
llama_context:      Metal compute buffer size =   284.01 MiB
llama_context:        CPU compute buffer size =    20.01 MiB
llama_context: graph nodes  = 1158
llama_context: graph splits = 2
time=2026-02-20T16:27:39.848-06:00 level=INFO source=server.go:1310 msg="llama runner started in 14.74 seconds"
time=2026-02-20T16:27:39.848-06:00 level=INFO source=sched.go:482 msg="loaded runners" count=1
time=2026-02-20T16:27:39.849-06:00 level=INFO source=server.go:1272 msg="waiting for llama runner to start responding"
time=2026-02-20T16:27:39.849-06:00 level=INFO source=server.go:1310 msg="llama runner started in 14.74 seconds"
ggml_metal_synchronize: error: command buffer 0 failed with status 5
error: Insufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)
ggml-metal-context.m:246: fatal error
(lldb) process attach --pid 24380
error: attach failed: attach failed (Not allowed to attach to process.  Look in the console messages (Console.app), near the debugserver entries, when the attach failed.  The subsystem that denied the attach permission will likely have logged an informative message about why it was denied.)
SIGABRT: abort
PC=0x180ada5b0 m=5 sigcode=0
signal arrived during cgo execution

goroutine 24 gp=0x14000003880 m=5 mp=0x14000100008 [syscall]:
runtime.cgocall(0x101bad2a4, 0x14000019c58)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/cgocall.go:167 +0x44 fp=0x14000019c20 sp=0x14000019be0 pc=0x101066fd4
github.com/ollama/ollama/llama._Cfunc_llama_synchronize(0xc7a43c000)
	_cgo_gotypes.go:931 +0x30 fp=0x14000019c50 sp=0x14000019c20 pc=0x1013c82f0
github.com/ollama/ollama/llama.(*Context).Synchronize.func1(...)
	/Users/runner/work/ollama/ollama/llama/llama.go:581
github.com/ollama/ollama/llama.(*Context).Synchronize(0x14000257500?)
	/Users/runner/work/ollama/ollama/llama/llama.go:581 +0x4c fp=0x14000019c90 sp=0x14000019c50 pc=0x1013ccb7c
github.com/ollama/ollama/runner/llamarunner.(*Server).processBatch(0x14000640140, 0x14000127090, 0x14000019f18)
	/Users/runner/work/ollama/ollama/runner/llamarunner/runner.go:482 +0x3a8 fp=0x14000019ed0 sp=0x14000019c90 pc=0x101474d28
github.com/ollama/ollama/runner/llamarunner.(*Server).run(0x14000640140, {0x10231dce0, 0x140005220f0})
	/Users/runner/work/ollama/ollama/runner/llamarunner/runner.go:361 +0x164 fp=0x14000019fa0 sp=0x14000019ed0 pc=0x101474814
github.com/ollama/ollama/runner/llamarunner.Execute.gowrap1()
	/Users/runner/work/ollama/ollama/runner/llamarunner/runner.go:909 +0x30 fp=0x14000019fd0 sp=0x14000019fa0 pc=0x101478900
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/asm_arm64.s:1223 +0x4 fp=0x14000019fd0 sp=0x14000019fd0 pc=0x101072254
created by github.com/ollama/ollama/runner/llamarunner.Execute in goroutine 1
	/Users/runner/work/ollama/ollama/runner/llamarunner/runner.go:909 +0x44c

goroutine 1 gp=0x140000021c0 m=nil [IO wait]:
runtime.gopark(0x0?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:435 +0xc8 fp=0x140001fd720 sp=0x140001fd700 pc=0x10106a4f8
runtime.netpollblock(0x140001fd7b8?, 0x10ee110?, 0x1?)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/netpoll.go:575 +0x158 fp=0x140001fd760 sp=0x140001fd720 pc=0x10102fab8
internal/poll.runtime_pollWait(0x12c2c7750, 0x72)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/netpoll.go:351 +0xa0 fp=0x140001fd790 sp=0x140001fd760 pc=0x1010696b0
internal/poll.(*pollDesc).wait(0x1400017ca80?, 0x1010f0378?, 0x0)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/internal/poll/fd_poll_runtime.go:84 +0x28 fp=0x140001fd7c0 sp=0x140001fd790 pc=0x1010e9928
internal/poll.(*pollDesc).waitRead(...)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/internal/poll/fd_poll_runtime.go:89
internal/poll.(*FD).Accept(0x1400017ca80)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/internal/poll/fd_unix.go:620 +0x24c fp=0x140001fd870 sp=0x140001fd7c0 pc=0x1010ee1fc
net.(*netFD).accept(0x1400017ca80)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/net/fd_unix.go:172 +0x28 fp=0x140001fd930 sp=0x140001fd870 pc=0x10115e058
net.(*TCPListener).accept(0x140000560c0)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/net/tcpsock_posix.go:159 +0x24 fp=0x140001fd980 sp=0x140001fd930 pc=0x1011722b4
net.(*TCPListener).Accept(0x140000560c0)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/net/tcpsock.go:380 +0x2c fp=0x140001fd9c0 sp=0x140001fd980 pc=0x10117129c
net/http.(*onceCloseListener).Accept(0x1400011dc20?)
	<autogenerated>:1 +0x30 fp=0x140001fd9e0 sp=0x140001fd9c0 pc=0x10134c5b0
net/http.(*Server).Serve(0x1400063e100, {0x10231b768, 0x140000560c0})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/net/http/server.go:3424 +0x290 fp=0x140001fdb10 sp=0x140001fd9e0 pc=0x101325cf0
github.com/ollama/ollama/runner/llamarunner.Execute({0x140001aa140, 0x4, 0x4})
	/Users/runner/work/ollama/ollama/runner/llamarunner/runner.go:930 +0x7ac fp=0x140001fdce0 sp=0x140001fdb10 pc=0x1014786dc
github.com/ollama/ollama/runner.Execute({0x140001aa130?, 0x0?, 0x0?})
	/Users/runner/work/ollama/ollama/runner/runner.go:22 +0x130 fp=0x140001fdd10 sp=0x140001fdce0 pc=0x1014eb5e0
github.com/ollama/ollama/cmd.NewCLI.func2(0x14000257200?, {0x101e6ce8c?, 0x4?, 0x101e6ce90?})
	/Users/runner/work/ollama/ollama/cmd/cmd.go:1769 +0x54 fp=0x140001fdd40 sp=0x140001fdd10 pc=0x101b5c2a4
github.com/spf13/cobra.(*Command).execute(0x140000c1508, {0x140001d9940, 0x4, 0x4})
	/Users/runner/go/pkg/mod/github.com/spf13/cobra@v1.7.0/command.go:940 +0x648 fp=0x140001fde60 sp=0x140001fdd40 pc=0x1011cc5f8
github.com/spf13/cobra.(*Command).ExecuteC(0x14000628f08)
	/Users/runner/go/pkg/mod/github.com/spf13/cobra@v1.7.0/command.go:1068 +0x320 fp=0x140001fdf20 sp=0x140001fde60 pc=0x1011ccd40
github.com/spf13/cobra.(*Command).Execute(...)
	/Users/runner/go/pkg/mod/github.com/spf13/cobra@v1.7.0/command.go:992
github.com/spf13/cobra.(*Command).ExecuteContext(...)
	/Users/runner/go/pkg/mod/github.com/spf13/cobra@v1.7.0/command.go:985
main.main()
	/Users/runner/work/ollama/ollama/main.go:12 +0x54 fp=0x140001fdf40 sp=0x140001fdf20 pc=0x101b5cde4
runtime.main()
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:283 +0x284 fp=0x140001fdfd0 sp=0x140001fdf40 pc=0x101036624
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/asm_arm64.s:1223 +0x4 fp=0x140001fdfd0 sp=0x140001fdfd0 pc=0x101072254

goroutine 2 gp=0x14000002c40 m=nil [force gc (idle)]:
runtime.gopark(0x0?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:435 +0xc8 fp=0x14000078f90 sp=0x14000078f70 pc=0x10106a4f8
runtime.goparkunlock(...)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:441
runtime.forcegchelper()
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:348 +0xb8 fp=0x14000078fd0 sp=0x14000078f90 pc=0x101036978
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/asm_arm64.s:1223 +0x4 fp=0x14000078fd0 sp=0x14000078fd0 pc=0x101072254
created by runtime.init.7 in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:336 +0x24

goroutine 18 gp=0x14000102380 m=nil [GC sweep wait]:
runtime.gopark(0x1?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:435 +0xc8 fp=0x14000074760 sp=0x14000074740 pc=0x10106a4f8
runtime.goparkunlock(...)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:441
runtime.bgsweep(0x14000110000)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgcsweep.go:316 +0x108 fp=0x140000747b0 sp=0x14000074760 pc=0x101021a58
runtime.gcenable.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:204 +0x28 fp=0x140000747d0 sp=0x140000747b0 pc=0x101015858
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/asm_arm64.s:1223 +0x4 fp=0x140000747d0 sp=0x140000747d0 pc=0x101072254
created by runtime.gcenable in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:204 +0x6c

goroutine 19 gp=0x14000102540 m=nil [GC scavenge wait]:
runtime.gopark(0x10000?, 0x10202d998?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:435 +0xc8 fp=0x14000074f60 sp=0x14000074f40 pc=0x10106a4f8
runtime.goparkunlock(...)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:441
runtime.(*scavengerState).park(0x102c0a380)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgcscavenge.go:425 +0x5c fp=0x14000074f90 sp=0x14000074f60 pc=0x10101f4ec
runtime.bgscavenge(0x14000110000)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgcscavenge.go:658 +0xac fp=0x14000074fb0 sp=0x14000074f90 pc=0x10101fa8c
runtime.gcenable.gowrap2()
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:205 +0x28 fp=0x14000074fd0 sp=0x14000074fb0 pc=0x1010157f8
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/asm_arm64.s:1223 +0x4 fp=0x14000074fd0 sp=0x14000074fd0 pc=0x101072254
created by runtime.gcenable in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:205 +0xac

goroutine 34 gp=0x14000184380 m=nil [finalizer wait]:
runtime.gopark(0x18000785c8?, 0x1000000000000?, 0xf8?, 0x85?, 0x10134ef1c?)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:435 +0xc8 fp=0x14000078590 sp=0x14000078570 pc=0x10106a4f8
runtime.runfinq()
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mfinal.go:196 +0x108 fp=0x140000787d0 sp=0x14000078590 pc=0x101014858
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/asm_arm64.s:1223 +0x4 fp=0x140000787d0 sp=0x140000787d0 pc=0x101072254
created by runtime.createfing in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mfinal.go:166 +0x80

goroutine 20 gp=0x14000102fc0 m=nil [chan receive]:
runtime.gopark(0x14000293540?, 0x14000510018?, 0x48?, 0x57?, 0x101132228?)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:435 +0xc8 fp=0x140000756f0 sp=0x140000756d0 pc=0x10106a4f8
runtime.chanrecv(0x14000228230, 0x0, 0x1)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/chan.go:664 +0x42c fp=0x14000075770 sp=0x140000756f0 pc=0x101006afc
runtime.chanrecv1(0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/chan.go:506 +0x14 fp=0x140000757a0 sp=0x14000075770 pc=0x101006694
runtime.unique_runtime_registerUniqueMapCleanup.func2(...)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1796
runtime.unique_runtime_registerUniqueMapCleanup.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1799 +0x3c fp=0x140000757d0 sp=0x140000757a0 pc=0x101018a7c
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/asm_arm64.s:1223 +0x4 fp=0x140000757d0 sp=0x140000757d0 pc=0x101072254
created by unique.runtime_registerUniqueMapCleanup in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1794 +0x78

goroutine 21 gp=0x14000103340 m=nil [GC worker (idle)]:
runtime.gopark(0x0?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:435 +0xc8 fp=0x14000075f10 sp=0x14000075ef0 pc=0x10106a4f8
runtime.gcBgMarkWorker(0x14000229490)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1423 +0xdc fp=0x14000075fb0 sp=0x14000075f10 pc=0x101017cec
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1339 +0x28 fp=0x14000075fd0 sp=0x14000075fb0 pc=0x101017bd8
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/asm_arm64.s:1223 +0x4 fp=0x14000075fd0 sp=0x14000075fd0 pc=0x101072254
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1339 +0x140

goroutine 35 gp=0x14000184540 m=nil [GC worker (idle)]:
runtime.gopark(0x0?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:435 +0xc8 fp=0x140001f0710 sp=0x140001f06f0 pc=0x10106a4f8
runtime.gcBgMarkWorker(0x14000229490)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1423 +0xdc fp=0x140001f07b0 sp=0x140001f0710 pc=0x101017cec
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1339 +0x28 fp=0x140001f07d0 sp=0x140001f07b0 pc=0x101017bd8
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/asm_arm64.s:1223 +0x4 fp=0x140001f07d0 sp=0x140001f07d0 pc=0x101072254
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1339 +0x140

goroutine 22 gp=0x14000103500 m=nil [GC worker (idle)]:
runtime.gopark(0x0?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:435 +0xc8 fp=0x14000076710 sp=0x140000766f0 pc=0x10106a4f8
runtime.gcBgMarkWorker(0x14000229490)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1423 +0xdc fp=0x140000767b0 sp=0x14000076710 pc=0x101017cec
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1339 +0x28 fp=0x140000767d0 sp=0x140000767b0 pc=0x101017bd8
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/asm_arm64.s:1223 +0x4 fp=0x140000767d0 sp=0x140000767d0 pc=0x101072254
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1339 +0x140

goroutine 3 gp=0x14000003500 m=nil [GC worker (idle)]:
runtime.gopark(0x0?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:435 +0xc8 fp=0x14000079710 sp=0x140000796f0 pc=0x10106a4f8
runtime.gcBgMarkWorker(0x14000229490)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1423 +0xdc fp=0x140000797b0 sp=0x14000079710 pc=0x101017cec
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1339 +0x28 fp=0x140000797d0 sp=0x140000797b0 pc=0x101017bd8
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/asm_arm64.s:1223 +0x4 fp=0x140000797d0 sp=0x140000797d0 pc=0x101072254
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1339 +0x140

goroutine 36 gp=0x14000184700 m=nil [GC worker (idle)]:
runtime.gopark(0x469e1b9caabcc?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:435 +0xc8 fp=0x140001f0f10 sp=0x140001f0ef0 pc=0x10106a4f8
runtime.gcBgMarkWorker(0x14000229490)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1423 +0xdc fp=0x140001f0fb0 sp=0x140001f0f10 pc=0x101017cec
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1339 +0x28 fp=0x140001f0fd0 sp=0x140001f0fb0 pc=0x101017bd8
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/asm_arm64.s:1223 +0x4 fp=0x140001f0fd0 sp=0x140001f0fd0 pc=0x101072254
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1339 +0x140

goroutine 23 gp=0x140001036c0 m=nil [GC worker (idle)]:
runtime.gopark(0x469e1b9bf748b?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:435 +0xc8 fp=0x14000076f10 sp=0x14000076ef0 pc=0x10106a4f8
runtime.gcBgMarkWorker(0x14000229490)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1423 +0xdc fp=0x14000076fb0 sp=0x14000076f10 pc=0x101017cec
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1339 +0x28 fp=0x14000076fd0 sp=0x14000076fb0 pc=0x101017bd8
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/asm_arm64.s:1223 +0x4 fp=0x14000076fd0 sp=0x14000076fd0 pc=0x101072254
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1339 +0x140

goroutine 4 gp=0x140000036c0 m=nil [GC worker (idle)]:
runtime.gopark(0x469e1b9ca9feb?, 0x0?, 0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:435 +0xc8 fp=0x14000079f10 sp=0x14000079ef0 pc=0x10106a4f8
runtime.gcBgMarkWorker(0x14000229490)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1423 +0xdc fp=0x14000079fb0 sp=0x14000079f10 pc=0x101017cec
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1339 +0x28 fp=0x14000079fd0 sp=0x14000079fb0 pc=0x101017bd8
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/asm_arm64.s:1223 +0x4 fp=0x14000079fd0 sp=0x14000079fd0 pc=0x101072254
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1339 +0x140

goroutine 37 gp=0x140001848c0 m=nil [GC worker (idle)]:
runtime.gopark(0x469e1b9ca96a4?, 0x1?, 0x64?, 0x35?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:435 +0xc8 fp=0x140001f1710 sp=0x140001f16f0 pc=0x10106a4f8
runtime.gcBgMarkWorker(0x14000229490)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1423 +0xdc fp=0x140001f17b0 sp=0x140001f1710 pc=0x101017cec
runtime.gcBgMarkStartWorkers.gowrap1()
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1339 +0x28 fp=0x140001f17d0 sp=0x140001f17b0 pc=0x101017bd8
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/asm_arm64.s:1223 +0x4 fp=0x140001f17d0 sp=0x140001f17d0 pc=0x101072254
created by runtime.gcBgMarkStartWorkers in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/mgc.go:1339 +0x140

goroutine 25 gp=0x14000003a40 m=nil [select]:
runtime.gopark(0x1400004fa60?, 0x2?, 0xa?, 0x0?, 0x1400004f86c?)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:435 +0xc8 fp=0x1400004f6c0 sp=0x1400004f6a0 pc=0x10106a4f8
runtime.selectgo(0x1400004fa60, 0x1400004f868, 0xb?, 0x0, 0x1?, 0x1)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/select.go:351 +0x6c4 fp=0x1400004f7f0 sp=0x1400004f6c0 pc=0x101049c94
github.com/ollama/ollama/runner/llamarunner.(*Server).completion(0x14000640140, {0x10231b948, 0x140000adc00}, 0x140000bd680)
	/Users/runner/work/ollama/ollama/runner/llamarunner/runner.go:658 +0xa20 fp=0x1400004faa0 sp=0x1400004f7f0 pc=0x101476300
github.com/ollama/ollama/runner/llamarunner.(*Server).completion-fm({0x10231b948?, 0x140000adc00?}, 0x1400004fb28?)
	<autogenerated>:1 +0x40 fp=0x1400004fad0 sp=0x1400004faa0 pc=0x101478cf0
net/http.HandlerFunc.ServeHTTP(0x140001d20c0?, {0x10231b948?, 0x140000adc00?}, 0x1400004fb10?)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/net/http/server.go:2294 +0x38 fp=0x1400004fb00 sp=0x1400004fad0 pc=0x101322718
net/http.(*ServeMux).ServeHTTP(0x10?, {0x10231b948, 0x140000adc00}, 0x140000bd680)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/net/http/server.go:2822 +0x1b4 fp=0x1400004fb50 sp=0x1400004fb00 pc=0x1013242a4
net/http.serverHandler.ServeHTTP({0x102317f30?}, {0x10231b948?, 0x140000adc00?}, 0x1?)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/net/http/server.go:3301 +0xbc fp=0x1400004fb80 sp=0x1400004fb50 pc=0x10133ff8c
net/http.(*conn).serve(0x1400011dc20, {0x10231dca8, 0x140002f8720})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/net/http/server.go:2102 +0x52c fp=0x1400004ffa0 sp=0x1400004fb80 pc=0x101320ebc
net/http.(*Server).Serve.gowrap3()
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/net/http/server.go:3454 +0x30 fp=0x1400004ffd0 sp=0x1400004ffa0 pc=0x101326080
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/asm_arm64.s:1223 +0x4 fp=0x1400004ffd0 sp=0x1400004ffd0 pc=0x101072254
created by net/http.(*Server).Serve in goroutine 1
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/net/http/server.go:3454 +0x3d8

goroutine 14 gp=0x14000184e00 m=nil [IO wait]:
runtime.gopark(0xffffffffffffffff?, 0xffffffffffffffff?, 0x23?, 0x0?, 0x10108dd30?)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/proc.go:435 +0xc8 fp=0x140001ef580 sp=0x140001ef560 pc=0x10106a4f8
runtime.netpollblock(0x0?, 0x0?, 0x0?)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/netpoll.go:575 +0x158 fp=0x140001ef5c0 sp=0x140001ef580 pc=0x10102fab8
internal/poll.runtime_pollWait(0x12c2c7638, 0x72)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/netpoll.go:351 +0xa0 fp=0x140001ef5f0 sp=0x140001ef5c0 pc=0x1010696b0
internal/poll.(*pollDesc).wait(0x1400017cb00?, 0x140002f88b1?, 0x0)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/internal/poll/fd_poll_runtime.go:84 +0x28 fp=0x140001ef620 sp=0x140001ef5f0 pc=0x1010e9928
internal/poll.(*pollDesc).waitRead(...)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/internal/poll/fd_poll_runtime.go:89
internal/poll.(*FD).Read(0x1400017cb00, {0x140002f88b1, 0x1, 0x1})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/internal/poll/fd_unix.go:165 +0x1fc fp=0x140001ef6c0 sp=0x140001ef620 pc=0x1010eabdc
net.(*netFD).Read(0x1400017cb00, {0x140002f88b1?, 0x140001ef758?, 0x10131b934?})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/net/fd_posix.go:55 +0x28 fp=0x140001ef710 sp=0x140001ef6c0 pc=0x10115c628
net.(*conn).Read(0x14000194148, {0x140002f88b1?, 0x0?, 0x0?})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/net/net.go:194 +0x34 fp=0x140001ef760 sp=0x140001ef710 pc=0x1011694f4
net/http.(*connReader).backgroundRead(0x140002f88a0)
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/net/http/server.go:690 +0x40 fp=0x140001ef7b0 sp=0x140001ef760 pc=0x10131b830
net/http.(*connReader).startBackgroundRead.gowrap2()
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/net/http/server.go:686 +0x28 fp=0x140001ef7d0 sp=0x140001ef7b0 pc=0x10131b718
runtime.goexit({})
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/runtime/asm_arm64.s:1223 +0x4 fp=0x140001ef7d0 sp=0x140001ef7d0 pc=0x101072254
created by net/http.(*connReader).startBackgroundRead in goroutine 25
	/Users/runner/hostedtoolcache/go/1.24.0/arm64/src/net/http/server.go:686 +0xc4

r0      0x0
r1      0x0
r2      0x0
r3      0x0
r4      0x1eeb14fc0
r5      0x480700000003
r6      0x2c
r7      0x0
r8      0x895c69e90ab408ba
r9      0x895c69e87a56b8ba
r10     0x0
r11     0x2
r12     0x0
r13     0x2
r14     0xffffffef
r15     0x10204ac62
r16     0x148
r17     0x1eeaf6008
r18     0x0
r19     0x6
r20     0x1c03
r21     0x170e2b0e0
r22     0x0
r23     0x2
r24     0xc7cafc340
r25     0xa
r26     0x14000019aa8
r27     0x818
r28     0x140001021c0
r29     0x170e2a5a0
lr      0x180b14888
sp      0x170e2a580
pc      0x180ada5b0
fault   0x180ada5b0
time=2026-02-20T16:27:57.478-06:00 level=ERROR source=server.go:426 msg="llama runner terminated" error="exit status 2"
time=2026-02-20T16:27:57.482-06:00 level=ERROR source=server.go:1496 msg="post predict" error="Post \"http://127.0.0.1:56028/completion\": EOF"
[GIN] 2026/02/20 - 16:27:57 | 500 | 44.880726375s |       127.0.0.1 | POST     "/api/generate"
